{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78101884-5162-4cc8-8bb2-365ffb3ead29",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e46ff342-eb74-4044-8e6a-e22d10c6086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.labels = data[:, 0]                                     # (n, 1)\n",
    "        self.pixels = data[:, 1:].reshape(data.shape[0], 1, 28, 28)  # (n, 1, 28, 28)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.pixels[idx], self.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34da2cac-1dbe-4947-8adf-dbdf7ab19ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomAffine(degrees=30, translate=(0.1, 0.1), scale=(0.75, 1), shear=30),\n",
    "    transforms.Normalize(0, 255)\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Normalize(0, 255)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "227c35d5-1b99-404a-b213-f4c857f87d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600\n",
      "8400\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('../train.csv').values\n",
    "train_data, val_data = train_test_split(dataset, test_size=0.2)\n",
    "train_set = MNISTDataset(train_data, transform=train_transforms)\n",
    "val_set = MNISTDataset(val_data, transform=val_transforms)\n",
    "print(len(train_set))\n",
    "print(len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4fff6a0-1241-48a9-b41c-19398088d1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, stride=1, padding=0)\n",
    "        self.fc1 = nn.Linear(5 * 5 * 16, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.conv1(x))\n",
    "        x = F.avg_pool2d(x, 2)\n",
    "        x = torch.sigmoid(self.conv2(x))\n",
    "        x = F.avg_pool2d(x, 2)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        output = F.softmax(x, dim=1)\n",
    "        return output\n",
    "    \n",
    "    def loss(self, output, label):\n",
    "        loss = F.cross_entropy(output, label)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a91fe03-177c-4f2a-aaa0-6167fca7a2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    print(\"Epoch %d\" % epoch)\n",
    "    model.train()\n",
    "    losses = []\n",
    "    \n",
    "    # iterate through batches\n",
    "    for i, (data, label) in enumerate(train_loader):\n",
    "        data = data.to(device = device, dtype = torch.float)\n",
    "        label = label.to(device = device, dtype = torch.long)\n",
    "\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = model.loss(output, label)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print loss every 21 batch iterations\n",
    "        if i % 21 == 0:\n",
    "            print(\"Batch Iteration %d, Train Loss: %.6f\" % (i, loss.item()))\n",
    "    \n",
    "    return losses\n",
    "\n",
    "\n",
    "def validate(model, device, val_loader):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    \n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for (data, label) in val_loader:\n",
    "            data = data.to(device = device, dtype = torch.float)\n",
    "            label = label.to(device = device, dtype = torch.long)\n",
    "            output = model(data)\n",
    "            loss = model.loss(output, label)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            pred = output.argmax(dim = 1, keepdim = True)\n",
    "            correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "            \n",
    "    val_loss = np.mean(losses)\n",
    "\n",
    "    print(\"\\nValidation Loss: {}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
    "        val_loss, correct, len(val_loader.dataset),\n",
    "        100. * correct / len(val_loader.dataset)))\n",
    "    \n",
    "    return losses, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "896b20c6-27e8-46c4-9e66-f98e21452f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n",
      "Epoch 1\n",
      "Batch Iteration 0, Train Loss: 2.302686\n",
      "Batch Iteration 21, Train Loss: 2.300240\n",
      "Batch Iteration 42, Train Loss: 2.298223\n",
      "Batch Iteration 63, Train Loss: 2.303801\n",
      "Batch Iteration 84, Train Loss: 2.300340\n",
      "Batch Iteration 105, Train Loss: 2.298844\n",
      "Batch Iteration 126, Train Loss: 2.301507\n",
      "Batch Iteration 147, Train Loss: 2.296229\n",
      "\n",
      "Validation Loss: 2.2927706227416085, Accuracy: 979/8400 (12%)\n",
      "\n",
      "Epoch 2\n",
      "Batch Iteration 0, Train Loss: 2.290710\n",
      "Batch Iteration 21, Train Loss: 2.275035\n",
      "Batch Iteration 42, Train Loss: 2.175604\n",
      "Batch Iteration 63, Train Loss: 2.102944\n",
      "Batch Iteration 84, Train Loss: 1.926192\n",
      "Batch Iteration 105, Train Loss: 1.823398\n",
      "Batch Iteration 126, Train Loss: 1.764542\n",
      "Batch Iteration 147, Train Loss: 1.735679\n",
      "\n",
      "Validation Loss: 1.689937487954185, Accuracy: 6575/8400 (78%)\n",
      "\n",
      "Epoch 3\n",
      "Batch Iteration 0, Train Loss: 1.695371\n",
      "Batch Iteration 21, Train Loss: 1.664338\n",
      "Batch Iteration 42, Train Loss: 1.675257\n",
      "Batch Iteration 63, Train Loss: 1.652160\n",
      "Batch Iteration 84, Train Loss: 1.663994\n",
      "Batch Iteration 105, Train Loss: 1.622632\n",
      "Batch Iteration 126, Train Loss: 1.702097\n",
      "Batch Iteration 147, Train Loss: 1.667461\n",
      "\n",
      "Validation Loss: 1.6336210653895424, Accuracy: 6972/8400 (83%)\n",
      "\n",
      "Epoch 4\n",
      "Batch Iteration 0, Train Loss: 1.642174\n",
      "Batch Iteration 21, Train Loss: 1.625578\n",
      "Batch Iteration 42, Train Loss: 1.675185\n",
      "Batch Iteration 63, Train Loss: 1.625553\n",
      "Batch Iteration 84, Train Loss: 1.623435\n",
      "Batch Iteration 105, Train Loss: 1.643009\n",
      "Batch Iteration 126, Train Loss: 1.627920\n",
      "Batch Iteration 147, Train Loss: 1.600250\n",
      "\n",
      "Validation Loss: 1.619779035449028, Accuracy: 7067/8400 (84%)\n",
      "\n",
      "Epoch 5\n",
      "Batch Iteration 0, Train Loss: 1.592429\n",
      "Batch Iteration 21, Train Loss: 1.624181\n",
      "Batch Iteration 42, Train Loss: 1.609830\n",
      "Batch Iteration 63, Train Loss: 1.647588\n",
      "Batch Iteration 84, Train Loss: 1.597764\n",
      "Batch Iteration 105, Train Loss: 1.638072\n",
      "Batch Iteration 126, Train Loss: 1.586523\n",
      "Batch Iteration 147, Train Loss: 1.629300\n",
      "\n",
      "Validation Loss: 1.5630959428492046, Accuracy: 7603/8400 (91%)\n",
      "\n",
      "Epoch 6\n",
      "Batch Iteration 0, Train Loss: 1.570181\n",
      "Batch Iteration 21, Train Loss: 1.551634\n",
      "Batch Iteration 42, Train Loss: 1.510333\n",
      "Batch Iteration 63, Train Loss: 1.524643\n",
      "Batch Iteration 84, Train Loss: 1.546136\n",
      "Batch Iteration 105, Train Loss: 1.562151\n",
      "Batch Iteration 126, Train Loss: 1.509040\n",
      "Batch Iteration 147, Train Loss: 1.529930\n",
      "\n",
      "Validation Loss: 1.5272848492576963, Accuracy: 7871/8400 (94%)\n",
      "\n",
      "Epoch 7\n",
      "Batch Iteration 0, Train Loss: 1.516063\n",
      "Batch Iteration 21, Train Loss: 1.525659\n",
      "Batch Iteration 42, Train Loss: 1.558051\n",
      "Batch Iteration 63, Train Loss: 1.543257\n",
      "Batch Iteration 84, Train Loss: 1.511067\n",
      "Batch Iteration 105, Train Loss: 1.542382\n",
      "Batch Iteration 126, Train Loss: 1.507656\n",
      "Batch Iteration 147, Train Loss: 1.507470\n",
      "\n",
      "Validation Loss: 1.5170660714308422, Accuracy: 7955/8400 (95%)\n",
      "\n",
      "Epoch 8\n",
      "Batch Iteration 0, Train Loss: 1.496417\n",
      "Batch Iteration 21, Train Loss: 1.518647\n",
      "Batch Iteration 42, Train Loss: 1.547961\n",
      "Batch Iteration 63, Train Loss: 1.520839\n",
      "Batch Iteration 84, Train Loss: 1.530679\n",
      "Batch Iteration 105, Train Loss: 1.528332\n",
      "Batch Iteration 126, Train Loss: 1.496954\n",
      "Batch Iteration 147, Train Loss: 1.509826\n",
      "\n",
      "Validation Loss: 1.5146982499531336, Accuracy: 7972/8400 (95%)\n",
      "\n",
      "Epoch 9\n",
      "Batch Iteration 0, Train Loss: 1.492998\n",
      "Batch Iteration 21, Train Loss: 1.506661\n",
      "Batch Iteration 42, Train Loss: 1.504435\n",
      "Batch Iteration 63, Train Loss: 1.499899\n",
      "Batch Iteration 84, Train Loss: 1.504401\n",
      "Batch Iteration 105, Train Loss: 1.502012\n",
      "Batch Iteration 126, Train Loss: 1.516398\n",
      "Batch Iteration 147, Train Loss: 1.505142\n",
      "\n",
      "Validation Loss: 1.5085265806743078, Accuracy: 8033/8400 (96%)\n",
      "\n",
      "Epoch 10\n",
      "Batch Iteration 0, Train Loss: 1.536333\n",
      "Batch Iteration 21, Train Loss: 1.509522\n",
      "Batch Iteration 42, Train Loss: 1.494881\n",
      "Batch Iteration 63, Train Loss: 1.503629\n",
      "Batch Iteration 84, Train Loss: 1.518124\n",
      "Batch Iteration 105, Train Loss: 1.509893\n",
      "Batch Iteration 126, Train Loss: 1.488550\n",
      "Batch Iteration 147, Train Loss: 1.500752\n",
      "\n",
      "Validation Loss: 1.5052402658121926, Accuracy: 8031/8400 (96%)\n",
      "\n",
      "Epoch 11\n",
      "Batch Iteration 0, Train Loss: 1.495027\n",
      "Batch Iteration 21, Train Loss: 1.485654\n",
      "Batch Iteration 42, Train Loss: 1.505379\n",
      "Batch Iteration 63, Train Loss: 1.511147\n",
      "Batch Iteration 84, Train Loss: 1.483372\n",
      "Batch Iteration 105, Train Loss: 1.491818\n",
      "Batch Iteration 126, Train Loss: 1.510790\n",
      "Batch Iteration 147, Train Loss: 1.517556\n",
      "\n",
      "Validation Loss: 1.501928605494045, Accuracy: 8070/8400 (96%)\n",
      "\n",
      "Epoch 12\n",
      "Batch Iteration 0, Train Loss: 1.509106\n",
      "Batch Iteration 21, Train Loss: 1.496208\n",
      "Batch Iteration 42, Train Loss: 1.486074\n",
      "Batch Iteration 63, Train Loss: 1.489694\n",
      "Batch Iteration 84, Train Loss: 1.499391\n",
      "Batch Iteration 105, Train Loss: 1.513633\n",
      "Batch Iteration 126, Train Loss: 1.507240\n",
      "Batch Iteration 147, Train Loss: 1.467271\n",
      "\n",
      "Validation Loss: 1.4988724213270914, Accuracy: 8098/8400 (96%)\n",
      "\n",
      "Epoch 13\n",
      "Batch Iteration 0, Train Loss: 1.504279\n",
      "Batch Iteration 21, Train Loss: 1.512272\n",
      "Batch Iteration 42, Train Loss: 1.485525\n",
      "Batch Iteration 63, Train Loss: 1.492535\n",
      "Batch Iteration 84, Train Loss: 1.508260\n",
      "Batch Iteration 105, Train Loss: 1.482284\n",
      "Batch Iteration 126, Train Loss: 1.479853\n",
      "Batch Iteration 147, Train Loss: 1.503093\n",
      "\n",
      "Validation Loss: 1.4996480494737625, Accuracy: 8094/8400 (96%)\n",
      "\n",
      "Epoch 14\n",
      "Batch Iteration 0, Train Loss: 1.513601\n",
      "Batch Iteration 21, Train Loss: 1.495570\n",
      "Batch Iteration 42, Train Loss: 1.494203\n",
      "Batch Iteration 63, Train Loss: 1.492256\n",
      "Batch Iteration 84, Train Loss: 1.489552\n",
      "Batch Iteration 105, Train Loss: 1.503684\n",
      "Batch Iteration 126, Train Loss: 1.504876\n",
      "Batch Iteration 147, Train Loss: 1.486237\n",
      "\n",
      "Validation Loss: 1.496701942313285, Accuracy: 8119/8400 (97%)\n",
      "\n",
      "Epoch 15\n",
      "Batch Iteration 0, Train Loss: 1.488535\n",
      "Batch Iteration 21, Train Loss: 1.525385\n",
      "Batch Iteration 42, Train Loss: 1.483403\n",
      "Batch Iteration 63, Train Loss: 1.501979\n",
      "Batch Iteration 84, Train Loss: 1.487018\n",
      "Batch Iteration 105, Train Loss: 1.501454\n",
      "Batch Iteration 126, Train Loss: 1.484873\n",
      "Batch Iteration 147, Train Loss: 1.484598\n",
      "\n",
      "Validation Loss: 1.4957130593912942, Accuracy: 8124/8400 (97%)\n",
      "\n",
      "Epoch 16\n",
      "Batch Iteration 0, Train Loss: 1.483345\n",
      "Batch Iteration 21, Train Loss: 1.491303\n",
      "Batch Iteration 42, Train Loss: 1.477773\n",
      "Batch Iteration 63, Train Loss: 1.510450\n",
      "Batch Iteration 84, Train Loss: 1.502705\n",
      "Batch Iteration 105, Train Loss: 1.490351\n",
      "Batch Iteration 126, Train Loss: 1.502878\n",
      "Batch Iteration 147, Train Loss: 1.494484\n",
      "\n",
      "Validation Loss: 1.4938404318832217, Accuracy: 8137/8400 (97%)\n",
      "\n",
      "Epoch 17\n",
      "Batch Iteration 0, Train Loss: 1.491733\n",
      "Batch Iteration 21, Train Loss: 1.490417\n",
      "Batch Iteration 42, Train Loss: 1.502163\n",
      "Batch Iteration 63, Train Loss: 1.495216\n",
      "Batch Iteration 84, Train Loss: 1.479495\n",
      "Batch Iteration 105, Train Loss: 1.484645\n",
      "Batch Iteration 126, Train Loss: 1.504203\n",
      "Batch Iteration 147, Train Loss: 1.488195\n",
      "\n",
      "Validation Loss: 1.494010974253927, Accuracy: 8141/8400 (97%)\n",
      "\n",
      "Epoch 18\n",
      "Batch Iteration 0, Train Loss: 1.488702\n",
      "Batch Iteration 21, Train Loss: 1.511898\n",
      "Batch Iteration 42, Train Loss: 1.495752\n",
      "Batch Iteration 63, Train Loss: 1.496087\n",
      "Batch Iteration 84, Train Loss: 1.502901\n",
      "Batch Iteration 105, Train Loss: 1.500697\n",
      "Batch Iteration 126, Train Loss: 1.518650\n",
      "Batch Iteration 147, Train Loss: 1.510718\n",
      "\n",
      "Validation Loss: 1.4933477782067799, Accuracy: 8146/8400 (97%)\n",
      "\n",
      "Epoch 19\n",
      "Batch Iteration 0, Train Loss: 1.489017\n",
      "Batch Iteration 21, Train Loss: 1.486772\n",
      "Batch Iteration 42, Train Loss: 1.507371\n",
      "Batch Iteration 63, Train Loss: 1.499230\n",
      "Batch Iteration 84, Train Loss: 1.504434\n",
      "Batch Iteration 105, Train Loss: 1.479486\n",
      "Batch Iteration 126, Train Loss: 1.499760\n",
      "Batch Iteration 147, Train Loss: 1.489737\n",
      "\n",
      "Validation Loss: 1.4936700016260147, Accuracy: 8146/8400 (97%)\n",
      "\n",
      "Epoch 20\n",
      "Batch Iteration 0, Train Loss: 1.478057\n",
      "Batch Iteration 21, Train Loss: 1.479567\n",
      "Batch Iteration 42, Train Loss: 1.493461\n",
      "Batch Iteration 63, Train Loss: 1.476156\n",
      "Batch Iteration 84, Train Loss: 1.491060\n",
      "Batch Iteration 105, Train Loss: 1.477897\n",
      "Batch Iteration 126, Train Loss: 1.481150\n",
      "Batch Iteration 147, Train Loss: 1.475822\n",
      "\n",
      "Validation Loss: 1.4922360330820084, Accuracy: 8163/8400 (97%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEGCAYAAAB2EqL0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAv50lEQVR4nO3dd5xU1f3/8ddnYSlKkaaCiKAhBrCgLIqxJprEaCwRNdii/kyM0cQSYyQd076WRA1fvxZsWFBjD0bBiIKIAgqy9C7Vpdelbzm/P+6dnZndKXd2d9rO+/l47GPv3HvuvZ+5LPOZc8+555hzDhERkWSKsh2AiIjkByUMEREJRAlDREQCUcIQEZFAlDBERCSQ5tkOIFWdO3d2PXv2zHYYIiJ5Zfr06Rudc10acoy8Sxg9e/Zk2rRp2Q5DRCSvmNmKhh5Dt6RERCQQJQwREQlECUNERALJuzYMEZH6qKioYPXq1ezZsyfboaRVq1at6N69O8XFxY1+bCUMESkIq1evpm3btvTs2RMzy3Y4aeGcY9OmTaxevZpevXo1+vF1S0pECsKePXvo1KlTk00WAGZGp06d0laLUsIQkYLRlJNFSDrfoxJGJOeg9AWoaNr3OEVE6kMJI9KisfDmT+GDP2c7EhFpYrZu3crDDz+c8n7nnHMOW7dubfyA6kEJI9Ke7d7vBW/DpAeyG4uINCnxEkZVVVXC/d555x0OOOCANEWVmsJLGBsWwjt3QHV1zapNM0azcerLELr3t2UZjBuWnfhEpEkaOnQoS5cupX///gwcOJBvfOMbXH755Rx99NEAXHjhhQwYMIB+/foxYsSImv169uzJxo0bWb58OX369OHHP/4x/fr149vf/ja7d+/O6HsovG61L/wAtixjW++LaDf6WgyjU3lZ7LJr50DzltC5d2ZjFJG0uuutucwr296ox+zbrR1/PK9f3O133303c+bMobS0lAkTJnDuuecyZ86cmu6vTz31FB07dmT37t0MHDiQwYMH06lTp6hjLF68mBdffJHHH3+cSy+9lNdee40rr7yyUd9HIgWTMMr3VPD6iD9z9ZZlALQfdXbynR49GYBt7fuw4cQ7+cpJF4ZrISIiDXDCCSdEPSsxfPhw3njjDQBWrVrF4sWL6ySMXr160b9/fwAGDBjA8uXLMxUuUEAJY8ys1Vy9+Z/12rf9tvm0/+81zN07gp09v8UJvTo2cnQikkmJagKZsv/++9csT5gwgXHjxjF58mT2228/zjjjjJjPUrRs2bJmuVmzZhm/JVUwbRiX9Gx4V9mR46Zx6WOTGyEaESk0bdu2pby8POa2bdu20aFDB/bbbz8WLFjAlClTMhxdMAVTw7Dxf23wMZZXHwzAvLLt9O3WrsHHE5HC0alTJ04++WSOOuooWrduzUEHHVSz7eyzz+bRRx/lmGOO4cgjj2TQoEFZjDQ+c85lO4aUlJSUuHpNoDRvNLx8VYPOfdm+3zK52qvKLr/73AYdS0Qya/78+fTp0yfbYWRErPdqZtOdcyUNOW7B3JJqjMbqIqqTFxIRaaIKJ2HQ8ITRXAlDRApY4SSMQ0+su27wk+HlfhfB+Q8lPEQzEj+RKSLSlBVOwmjTBYZtg59+El539MXh5UuehmOHJDyEkV/tPSIijalwEkbIQf3gji/gj1u9163aQ7fjvGVrFi531l3Q+9ve8hWvAtC6RXh7dbWSh4gUloLpVhtl/4inJ4euDC8XFcF5w6HnKdDpCDjpJqjcA5uWAPDQZcfzn6e9dowq5yhqhHYREZF8UXg1jGQGXO0lC4BmxdCybcxia7ZqzgwRSZ82bdpkO4Q6lDDq6bT7xmc7BBGRjCrMW1L1lWcPOYpI7rjzzjs57LDDuPHGGwEYNmwYZsbEiRPZsmULFRUV/OUvf+GCCy7IcqTxKWEEorYKkSZlzFBYO7txj3nw0fDdu+NuHjJkCLfeemtNwnj55ZcZO3Yst912G+3atWPjxo0MGjSI888/P2fnHlfCSNHXDm7LgrXldGnbMnlhERHfcccdx/r16ykrK2PDhg106NCBrl27cttttzFx4kSKior48ssvWbduHQcffHC2w41JCSNF/bq1Z8HacjaU78U5l7PfBEQkgQQ1gXS6+OKLefXVV1m7di1Dhgxh1KhRbNiwgenTp1NcXEzPnj1jDmueK9TonaK/XHhUzfKULzZnMRIRyTdDhgzhpZde4tVXX+Xiiy9m27ZtHHjggRQXFzN+/HhWrFiR7RATUsJIUeTDe794uTR7gYhI3unXrx/l5eUccsghdO3alSuuuIJp06ZRUlLCqFGj+NrXvpbtEBPSLamURPeSWrs9d6uOIpKbZs8ON7Z37tyZyZNjT8q2Y8eOTIUUmGoYQcRpp1AvWxEpJEoYIiISSNoShpkdambjzWy+mc01s1tilLnCzGb5P5+Y2bHpikdEJN9mGK2PdL7HdNYwKoHbnXN9gEHATWbWt1aZZcDpzrljgD8DI9IYj4gUsFatWrFp06YmnTScc2zatIlWrVql5fhpa/R2zq0B1vjL5WY2HzgEmBdRJmJyCqYA3dMVT6Nown9oIk1d9+7dWb16NRs2bMh2KGnVqlUrundPz0dpRnpJmVlP4DhgaoJi1wFj4ux/PXA9QI8ePRo7vAD0cJ5IvisuLqZXr17ZDiOvpb3R28zaAK8Btzrntscp8w28hHFnrO3OuRHOuRLnXEmXLl3SF6yIiMSV1hqGmRXjJYtRzrnX45Q5BngC+K5zblM64xERkfpLZy8pA54E5jvn7o9TpgfwOnCVc25RumIREZGGS2cN42TgKmC2mZX6634D9ABwzj0K/AHoBDzsD+JX6ZwrSWNMIiJST+nsJTWJJK3FzrkfAT9KVwyNT72kRKRw6UnvIBIMYf7pMo1YKyKFQQmjHt6++ZSa5eufm5bFSEREMkcJox76dWtfs7x9d0UWIxERyRwljAaqVrOGiBQIJYxURAwN8quzj8xiICIimaeEEUjdRu8izeUtIgVGCaOeipQvRKTAKGHUk2oYIlJolDDqyZQwRKTAKGGIiEggShgpUR9aESlcShhB6PaTiIgShoiIBKOEISIigShh1JNuUolIoVHCqKfI5m/n1BguIk2fEkYq4iSGBWvLMxyIiEjmKWEEUvcGVOQaVTBEpBAoYdTT4AHda5bV61ZECoESRj21b11cs6yEISKFQAmjEVRXZzsCEZH0U8JISezGiiufnJrhOEREMk8JI4gk95w279yXoUBERLJHCaMBDuu0X7ZDEBHJGCWMBji738E1y8NGz81iJCIi6aeE0QBHdGlTszzyk+XZC0REJAOUMBrgtK92yXYIIiIZo4SRilqPdBfp+QsRKSBKGIHEzgxFyhgiUkCUMBqgSI94i0gBUcJoAFUwRKSQKGGIiEggShgpiW701rDmIlJIlDCCiNNW0ayZ7kmJSOFQwmiAdq2KkxcSEWkilDBERCQQJQwREQkkbQnDzA41s/FmNt/M5prZLTHKmJkNN7MlZjbLzI5PVzwiItIwzdN47Ergdufc52bWFphuZu855+ZFlPku0Nv/ORF4xP+dm9QtSkQKWNpqGM65Nc65z/3lcmA+cEitYhcAzzrPFOAAM+uarpjqT72hRERSShhm1sHMjkn1JGbWEzgOqD2X6SHAqojXq6mbVDCz681smplN27BhQ6qnT6th5/XNdggiIhmRNGGY2QQza2dmHYGZwNNmdn/QE5hZG+A14Fbn3Pbam2PsUue+j3NuhHOuxDlX0qVLbg0prptUIlIogtQw2vsf9BcBTzvnBgBnBTm4mRXjJYtRzrnXYxRZDRwa8bo7UBbk2LlCzRoiUiiCJIzmfrvCpcB/gh7YzAx4EpjvnItXIxkN/NDvLTUI2OacWxP0HLlA+UJECkWQXlJ/At4FJjnnPjOzw4HFAfY7GbgKmG1mpf663wA9AJxzjwLvAOcAS4BdwLUpRZ8pCYYxdxFVjMqqapo306MtItI0JU0YzrlXgFciXn8BDA6w3ySSdC9y3qftTcnDzA8L15XTr1v7bIchIpIWQRq97/UbvYvN7H0z22hmV2YiuHyj9gwRacqC3D/5tt/o/T28RuqvAnekNao8VVWtjCEiTVeQhBEakvUc4EXn3OY0xpN3Im9BVamKISJNWJBG77fMbAGwG7jRzLoAe9IbVo6KkRBOOqJTxGYlDBFpupLWMJxzQ4GTgBLnXAWwE29IjwISbGiQ0lXb0hyHiEj2BGn0LsbrHvsvM3sVuA7YlO7A8tE9YxZkOwQRkbQJckvqEbx2jIf911f5636UrqDy1b6q6myHICKSNkESxkDn3LERrz8ws5npCkhERHJTkF5SVWZ2ROiF/6R3VfpCym8L1tYeX1FEpGkIkjDuAMb7o9Z+CHwA3J7esHJV8l5QVz7xaQbiEBHJvCBDg7xvZr2BI/G6Cy1wzu1Ne2S5JMFYUgCnf7ULHy4KzdOhrrUi0jTFTRhmdlGcTUeYGXGGKy9Ij145gD5/GAtoeBARaboS1TDOS7DNAUoYvtYtmtUsK1+ISFMVN2E453JzqPEcdXa/gxk7d62e9haRJkuTN6QiQTIo8q+k0oWINFVKGI3E/IbxPRXqcSwiTZMSRiMJ9aPaU6GnvUWkaQrypDdm9nWgZ2R559yzaYopLxUl6XorIpLvkiYMM3sOOAIoJfyEtwOUMCI0K1LCEJGmLUgNowTo69T9J6HIdFFd7ShSAhGRJiZIG8Yc4OB0B5If4udMi7gltWXXvkwEIyKSUUFqGJ2BeWb2KVAzJIhz7vy0RZVrArRPRBbZta+KTvGLiojkpSAJY1i6g2gKqqvDtQ91rRWRpijI4IMfZiKQfLe3MtyddvH6HfQ+qG0WoxERaXxBpmgdZGafmdkOM9tnZlVmpkkfatlbGa5V3Djq8yxGIiKSHkEavR8CLgMWA63xpmZ9KJ1B5awEHcUiaxgiIk1RoCe9nXNLgGbOuSrn3NPAGWmNKuckb/Q+tvsB6Q9DRCSLgiSMXWbWAig1s3vN7DZg/zTHldvG/gb+fGDUqp+f+ZWa5SPsSygrzXBQIiLpFSRhXOWX+xmwEzgUGJzOoHLelP+DquhJB1s2D8+J8X7LO2DE6ZmOSkQkrYL0klphZq2Brs65uzIQk4iI5KAgvaTOwxtHaqz/ur+ZjU5zXCIikmOC3JIaBpwAbAVwzpXijVxbgDSclogUriAJo9I5ty3tkeQyDV0uIhJoaJA5ZnY50MzMegM3A5+kNywREck1QWoYPwf64Q08+CKwHbg1jTHlj3VzYfnHNS//OaR/9mIREUmzpAnDObfLOfdb59xA51yJv7wnE8HlvEe+DiPPqXl5Qf9DshiMiEh6BeklVWJmr5vZ52Y2K/QTYL+nzGy9mc2Js729mb1lZjPNbK6ZXVufNyAiIpkRpA1jFHAHMBtIZcCkkXhjTsWbyvUmYJ5z7jwz6wIsNLNRzrncnX1Ikw6KSAEL0oaxwTk32jm3zDm3IvSTbCfn3ERgc6IiQFvzpqpr45etDBR1xgXoJbX5i9QOub0Mpo+sVzQiItkQpIbxRzN7Anif6Bn3Xm/guR8CRgNlQFvgB865mDUYM7seuB6gR48eDTxtGiwZB88PhsFP4g3o69m0Yy+d2rSMvc/zF8P6uXDkudCmS2biFBFpgCA1jGuB/sDZwHn+z/ca4dzfwXuCvJt//IfMrF2sgs65EX6De0mXLjn44bpyqve7bEbU6hemroy/z66N3m+n2flEJD8EqWEc65w7Og3nvha42znngCVmtgz4GvBpGs6VXhPv9X5Pfgj4es3qf7y3iJ+f2Ts7MYmINLIgNYwpZtY3DedeCZwJYGYHAUcCKTYEZFryRu8WVGQgDhGRzAtSwzgFuNqvAezFawF2zrljEu1kZi/iTbTU2cxWA38EivF2fhT4MzDSzGb7x7zTObexvm8krVIYGuTcoinBCqrHlYjkmSAJ4+z6HNg5d1mS7WXAt+tz7FzW3LLYJrFlOYw4A348Hjr2yl4cItIkBXnSe0Wsn0wEl5MqdifcXEx0wli1eRf/mVWWzojCZr4Eu7fAzBczcz4RKShBahgSac3MhJtvb/seRAyccu7wj9i+p5LvHdMtzh71HAl38zIoag4HHBpep9tcIpJGQRq9JWTum96HdAKd9kR3pd2+J8VnESf/HwxrD1VJGs+H94cHj4qzUcOxi0jjU8JIxZL3kn+QN9T4//F+V+xK73lERFKkhBFIxDf2omaB9zqjaEbyQnu3Q3UVvHkTbFhEuOuuagkikluUMIKoihgPMcktqUgjW9xHN+L1FPYTw/ODYe0sKH0eXrsu3A6hWf5EJMcoYQQRmTD2bk9p19a2N3GBrSuIrk2ohiEiuUkJI1XPXpDGgzvVMEQkZylhBNGA7qrm1xhc7WNEvvaTw659VVTHHrBXRCTrlDACafjzDXVyTmRiWPoBAMs37qSiMknCqNwL/7oy3lm8X6qdiEgaKGEEUV3/4T762XKgVsopfRF2R8wtNW4Y4NVGWprfbTderWbFxzD/rdjbnNo/RCR9lDCCaMBton+2eJgiqqmsjjjGnFdjlu1TlGD+DBGRLFPCCKKBkxzd0vw1jvzd2Ig1QWoAGuZDRHKLEkYQ1Q1riL6l+Ru08me3/f7DHzPli03Jd9K4UCKSY5QwguhwWIMPsaDVtbB3BzNWbmV3RUNqLHFqJ5V7wzP/iYikgRJGEG0ObJTDvHzfDbRjZ8DStWoYr/3IG5QwlmHtvXkwRETSSAkjgy6tfIvpLW8IVLaqulbCmP2KvxDnVtX6eeHlj/7uDX8uItKIlDAyrNiqcAEavXfuCzgsemmMyZKq9sFjp6UYmYhIYkoYWdCC5EOkt3vwCF5+8UkA1m8Pz8i0Y2+t9o8349RYUhzzSkQkGSWMLDil2dxA5S5d+AsAVi5fVLPuJ89PT0tMIiLJKGHkun27KHn91EY95JjZazjlng+orKqGlVNg7huNenwRaZqUMHLdruj5NIK0f9RY9G7M1UNfn83qLbsp31MJT30HXrmmAQGKSKFQwsh1Dx4d9dJSeQL8hUtjrg6NnKsxCkUkFUoYBcw0SKGIpEAJI6j9G+fhvYa6p/jxBh9Dg46ISH0oYQQ1KNgDd+nW3eLNER7bjr0xnueIMQr6noqqYGNciUjBUsIIKk9nwvvtG7NZs20388piPJcRUdUYNnouQ0ZMYcn6HZkLTkTySvNsB5A38nT02H+XlvHv0jIA3rvtNHof1LYmT1RHvKf5a8sB2LY7+UOFIlKYVMMIKk9rGJG+9cBEzn9oEjv2VtLXltNi5rPhjX7yGPzIJ2zcsTdLEYpILlPCCCpPaxjNiB5KpHvZuxxpK3mn5W/Y/7+316zfUxFOiNc8/SmzVm/NVIgikieUMALLz4RxWtGsqNcPtxjOuy2H1im3ede+muU5X27nh099mvbYRCS/KGEElae3pB4tfoBetoYXiv/CcbY4brmN5buJTIrNi/SMhohEU8IIKk8TRkurZHzL2/l6s3ncneAZjsktf86klrfUvN64Yx+Pfrg0EyGKSJ5QwggqTxNGUAfbFrrbRo62L2rW3T1mQRYjEpFco4QRVKJG71Nvj78tz7zV8nccausSF1o41psWdsuKzAQlIjlBCSOoRDWMLl/LXBwZ8FHL2xIXmPmC97vs8/QHIyI5QwkjqFDC6Pd9aN6q7vY+52c2nnpIZaTbU4tmcQgb0hiNiOSbtCUMM3vKzNab2ZwEZc4ws1Izm2tmH6YrlkbV7XjYv0v0OufgB8/BsG3ZiSkNnmtxN+Na3sHOWGNRiUhBSufQICOBh4BnY200swOAh4GznXMrzSw3hoONJ1TDsKK8bQAvSvFZkta2j5dnrWHZpp2s3LyL/7v8+DRFJiL5IG01DOfcRGBzgiKXA68751b65denK5ZGEWr0jkwYzVqGNsbf77iroFPvtIYW1FeKylLex+F4ZMJS3p61BsrXeo3d8/8Tf4e1s70y9/drQKQxbFmevMzKqd6518at1IpIA2SzDeOrQAczm2Bm083sh/EKmtn1ZjbNzKZt2JCl++qRNYwqf4C+nif722IkjBsmwS/mwwUPwRUvZybGNIh6a2Wl/sqqWEU9j57i/d6+uvGCWDgW/nkszH8rcbn5o73fSz9ovHOLSI1sJozmwADgXOA7wO/N7KuxCjrnRjjnSpxzJV26dIlVJP0iE0a1f1+/KM4dvRZt4eCjoV03f0X+PjXtgG5sxKimTk2qcm84iTSGHRtgyft116/1hzdZMzPggfJzGBeRXJfNhLEaGOuc2+mc2whMBI7NYjxJhG5JGVT737CLiqO3AfxmDdxRawgOy9/OaI+/8S6ftLqZG5rFuA01+ucw4nQY/zfvFlRVPYZG370FxgyFyn3wzPfg+Ytg9fToMkEHfgxNUp6nA0WK5LpsfpL9GzjVzJqb2X7AicD8LMaTWOsO3u+W7cI1jGYxahgt9oPi1tHrLH9rGN3NuwV4UtFcVs6dEr2xyh+w8MN7vFtQw+vRKD7uLpj6CMx+GTb4T5Y/8U2orvYSUGXkUOtJrmNlaABFJQyRdEhnt9oXgcnAkWa22syuM7MbzOwGAOfcfGAsMAv4FHjCOZe7rZWn3QHn/gOOvgTO8Ed7DT2PkfQbbf4mjFDPqmqK6DHrwcSFt61M/QShWkmdnmcO/ncA/OXA6HVblsOuzTDj+ejG9yXj4NPH/GIpJoyqCnjoBK+tRETiSlu3WufcZQHK3Afcl64YGlXzljDwR97yKbd6P2/8NJsRZcTxRYsAOKNZ0PaDOHZuhFVT4aXL4axhcMptsHsrMScYB+9Df6s/9EhkDe2fx3rPwez0Oz98529w1GBYOj7x+dfM8m6fHXcVnD+8VmwbYONC+M+tcGSGx8/augp2rIPuJZk9r0g95O/N9ZzSwFsg3/hd44SRBjc3f7NxDjTqEi9ZAIz/H/j8WbjnMJj5orfOjKikEVnjCNUY9vgPRu6M6Cn37m/g5R/Wuu0X49/jsVO9Y37+TPT65R+Hb63FMv5vMOXRRO+sYR48Cp44M33HbwwbFsGH92Y7CskBShgNEbhtIklCOf2OBoeSi8Y9fy/s3OS92BQxVHrVXq/BHMKJYe0coq5TrHGqPh0R+0R7thGdbJJc73d+BX/q7NU6Rp4D7/0hftkP74Gxd9Zdv70M1s3zenVVJ+hm3BQ88z0Y/1evg4IUNCWMhvjm76HPed74Uonk6ZPhDXXWkr/Cq9d6XW/3Jhk2Zeoj0a+f+k4KZ7LkNYxInz4G1RXhmsr6ALehpo6AB472ktGebXB/H3jkJHj+ItzEv8fep7q6aSSTij3ZjiDzFo+DccOyHUXOUcJoiHZd4QfPQ4v9E5cLfeM9oAec98/0x5VLln3otR2kk1l01+VU7xBuXOj9Ll8Dq+JMTTvmDq9Rf9qTcHePqE1Tpk+Pvc8rV8OfOkavW/AOVOyuW3bUJbGPMeVR77YZeO037/85zpuI4BxMeiBcuwN4/Jvwt+7R5fbthOe+H137A69b8/ZYowLUqlFPuAeWT0oez7q5ycvE4hy8eDl8MaF++zfEqMHeNZz7Jqz6LPPn37UZSl/I/HmTUMLIiIiG3eL9ojeFuuvWVxMa8DC+AL3QVk9Lobxvxcd11z35LdiRYJSaeaPrrDqp/F0ojzGHyPyIsluWw5fT4aXL4O1f1v0QXfzf2Ocbe6d32yx0jI/+7rUB7S33ai8bl9TdZ8Un3rfj+w6Hf/Tx1n05HfaVw/19vR5l4P1e+kHdW3JPfBOGHxexwr+elXu9JLPoXe/DfMLfYOS5seMOmfdveOTrMOe1xOVi2bcTFr4NL/wgWGIK+exJWN9IPfRfuRqePKtxjpWK138Mb/7Uaz/KIekcfFBqi2zY7Xyk98223SF1y135Gjw/OMFxmiUenqOJmbFyC8clKrC+1odv0G61H/0j9vpdm6FNnLEwK+Pcnnn/T3Dh/8Xe9rfu3of1sX6jf+nz3s9xVwaLE2DP9vDyh3fD7s3Qog1Muh96nQ5Xvh5+LiiyEb+8DLZGdHfe/qX3tzVsW+IHSmO9z39EDMTQ8fDY+80bDbs2Qsn/816HbvdFfoDPGw3Tn/aeZ7o6yXAvoVhGngtXvAq9v5W8/Nu/AAw6HAbtD/V65R3Ur+7zUeky900v0ZzyC++25wUPBd9391Z48JjwLdyqvQmLZ5pqGJkQ6wMsUYN594GJj9esRfTr5v5/BGsWvf6r300eWx447otUeyk5WPRfWDjGexmkjSLStlUxaxJA/NsrSz/whjbZvKzuv/e+cu937Yb8Gc9HvZxXtp112/0P6r3lMO3p8MY3fhK9b8VuWDnZW172IaxOcNvkwaNjrw8ljPq0sW3+Ivb6l6+C/9wGT5/jDVYZ+jvfvdVry9q22iuz9ANYNjF63307w0PNbF9T99jbv0weV6gnXeiZneUfeb3QRt+cfN/GEvp3nXQ/zHgutX3LZkS39+XYKBG5FU1TFbrt9LXvhds7Et6K8v+TtWjjPWdQW/NaCeOWUm+wwz9uhl8tC6+//KX6RpzXNiyaAi9cAi8O8W6jPHxiagcYdbH3oRbLvh2x15eXwd+/AsP7w10HeCPn1gksceI6Z/hHnHqP/zzJmDu950JCFr4TXdgsnDDAu21VXe097R6k996Ee8LdnOM1zL9+vVc72rs99vZEVnwML1/ttQsBfPa415ZVmeAb8yvXemWWjof7vxbucl0jwPuq1b5UY02p16bzr6v8539qb5/pJekpj8Lkh2Mfo2K39++ytzxxDPES8LYvo9uVIu3aDG/fHqOLd2499KuEkQn7dYRfLoFv/QmO/C6c83dvGep+G63dJnHSTdGvj7sKrnozel3bg73BDkPnKnBdyiIe4qvO0gRQY36V8i6/bj6KRcVDYMaoxO0owL7KWh9KrtpLcn/pwr7KALcrJ0R8EVn8LnwS47bJrH+Fa0f1sWoKTHsqOsxY35jXL/A+SFf7HQ7e/oX3e9xd0eXMvLLj/yfcUL9ubsDuvgafDPfalaY9Gb2pch88dpqXQMfeCe/+OvYhPn0cpj7qNYZX7I6+1Qdee82oS4nbhvZAX69dKZb3/wSfPRFdq8xBasPIlDYRo+ye8OPEczbU/obY7hBodQAcPRhOvT0t4TVVbsE7WfmOVrFjE8XJi0X5SfO3vYVJ98dvI/BVx3pXC7yhUl6dvprLUzw3//0ttO8O/S5MdU+/V9b9cPw1SYtOXbGdQbVXPnxi9CyWodtdsZJVqLb44d2svaWMgx/5OhzYF26cXLdspMo9UOTfsp3zupckBl7nxd6qnbd+RYJjbF0F7/3eW/7oH96ts6Xve1/wJj0IrQ+At27xth92cvS+FXugOGJa5+1lXsP8GUO923ZbloVrJYvGRO9r5t2q27czfrtaBilhZJ3/baTj4d4fftQmf9sv5mU2pCbEXv9R/XduwKi3xeWr6n9eLOm5E23dvLWePedeuRq6zkh5t+qR51G04iP2fPExMWa7j9J9RnRHg227K2gPXuNwsh6DG6NHgT7tnvdY1ApYP89LAB8n6LK+dUW4zWTdHO/nw7u9179d67+RBKMt/6tWB4WlEcPwj/tj9Lbave8eO80blDTkfr/nWofD4J07vGT2lXg9sYwtw0+lw46lcOYf4aiLoEPP+HGmmW5JZUvbg73foYf+bp4BQ0b5G0PfHjXqajY98uRj2TnxpsVs2514qPjWs+I3pv5s3e/rf+5EsynGUbTiIwB2fhHnGZYI3Vf+O/p0E18Nv0iWoD+JHgOsl0U0jH/2OIz/S+L943UMCPLFYE1p7PXVAToMbFzoNWbXtm9XuDdaqKtzLXMeu9ZLFgDv35X1W1aqYWTL/p3h16u9hu3aQlXnmgmYYjj/fxv3m8Y170C34+BvXRvvmHnup6tjDAmSIe2/nJCdE79X/2TTnNS7eg+afEP4xZ6tKe37bsuh4Rf7dqV87pDHJi7lJ8mLxXT9M1OJM2BNcrGGnKnlqKpadxfiTdqWIUoY2dSybez1xa1h8JNw2Nfj73t83Blt6y+P5+2Q7Gtv9f/Qbqi988fQsp77Lhn/LCk3OPn2X/xvaJG8XKNRwpCYjr44s+erPVqsSB5puTbO8CwB3Fdc7zoCD7R4JHmhRlRBUX1zW6NQG4aEFSdrshSRbBo5uSGdKRpOCaOpu/gpb4iCZBo6ppWIpN36ndkdEkgJo6k7ajCcFdHtL7J//1nDoM/5cO0YONDv6nfTZ3Bd7B4bIpJdMZ+/ySC1YTRFfS+ENgfF3nbzDBjW3ls+5ba627t8te46ERGUMJqmS5+pu65r//h9yRtD81bxR3IVkUbRo+N+yQulkRJGobj6rfAMc9eNg/YxhlWPZdCNMCXOYGwhpw/1hmGe9EDDYhSRhK44Mc7gihmiNoxC0aoddDrCWz50YOKHAiOd/T91B0QMjaDbvDX86AM4/VfQ1j9en/MaJ14RqaM52Z3uWQlDYru5FH7yUfj1N38XXj7pJvjZNLh1NnQf4D2ZPvA6r0fWJc8S6HmOhswU2LkB7Szte3hDwTema95u3OOJxJPl275KGBJbx17Q9Zjw69PuCNciADr3jh6Bt6iZ1yOrqIiaMbDa1ZpDOuQEfyCGW2fDnSvgdn8aytYdoe8F0WUP/0bd/ffrFPu4Z90Ve32kbv3DQ8HHc8nI+NtuiDGta30mIGpssYaYyZTrP8zeuQtNVeIxxtJNCUOCu/ETr5dVMr1O937/ZCL8tNaQ0YeeGK6tHNDDGxY6NKlUj0HRtYeffASt2tc9/mUvwTFDYOhKr6bylbOg5Do4+RZv+PfT74QTro8R12nxp8vsearXa+zMP4YHhAxp1sKbUveU28Kx1t4ecscX0Kl3nSI7B/3Si/WEZKMWJaid/W5D/G0desLZ98Tf/oNR8bclUdk7ycyNXY+Nv+3wM+AXKc54GFS7Q+CoNI2IcGzKA8TX2NEtwZA+DZXlIc6VMCS41h2SztMAwA+egxunwv6d4KC+3i2bXqd58ytf+Vp4/oGQlm2820SDn4Cv/xwG/ti7Jdb1GCi5NrrsISVekrnosXAyufI1+N793vAmZ/4BvvEbOOc+uCSit9ixl3sN/6F9DvJrGT/5CK56w4v5rGFwqv+Q48m3hPf9/Qb42afe9o69wut/Ng2+e6+XBEP27xRzlsT9e/i1tV6nhlcedkr0PBC/XQt/2BzjggJFxdAswaAQBx3l3RaMp8/3wu/95hlwx1JvBshIvU6LuWvzwyPW97vIe79DXgivSzQGWdf+0M4f0LJlezjim9FTEJ98C7RNMODlRY/H33becDjm0vjbz/l7/G0XPAzXvRd/+1nDwstHDa67/chz4firY+7apk+AecfjqOjcN3GBgQ0Yrr8xOOfy6mfAgAFOCtC2L51bN9+53duC71Nd7dykfzpXvr7utqoq56oqE+87+1Xnykrrbitf79yc16PXLRjj3MYl4ddTHnNu8XvOVex1btYr3vFCSl+Kjmnbl85tXhZ+vWWFc5MeDL/X8nXO7drsLW9Y5Nzyj6P3HX2Lc/t2e6/XznFu4bvOrZnl3N6d3vrQvuXrnZs2MjruKY85VzYz/Hryw84tes+57WvD66qqnPvoAef++3vn9u0Kr5/0oHPz3gpfr7lvOvf5886NGercjg3OLf/Eucp93vbZrzq36Yvwvl/O8K6Dc87t3urcov86t+R95z55yLl5o73ru36ht336M84tHhfed8Mi5+b+O/x67Rwv5qfO8fZdOj5cfvE47zx7d3jXony9c+Pu8t6Tc84tHOvcK9c69+kT3jXbscGLxTnn1i9w7rXrvb+TLSu9fT57MvpvcOa/vPe86jPntq9x7sP7vH/zPdudG/Nr53Ztce7Lz73rWVbq/Vs651xlhRfHpH8698S3ndu5ybnZr3nlqqqc+9cPnVs1zbk1s73ruHJq9DWoB2Caa+Dnr7kGTBKTDSUlJW7atGnZDkNEJK+Y2XTnXElDjqFbUiIiEogShoiIBKKEISIigShhiIhIIEoYIiISiBKGiIgEooQhIiKBKGGIiEggeffgnpltAFbUc/fOwMZGDCdT8jFuxZw5+Ri3Ys6MyJgPc851SVQ4mbxLGA1hZtMa+qRjNuRj3Io5c/IxbsWcGY0ds25JiYhIIEoYIiISSKEljBHZDqCe8jFuxZw5+Ri3Ys6MRo25oNowRESk/gqthiEiIvWkhCEiIoEUTMIws7PNbKGZLTGzodmOJ5KZLTez2WZWambT/HUdzew9M1vs/+4QUf7X/vtYaGbfyVCMT5nZejObE7Eu5RjNbID/XpeY2XCzRPN7pi3uYWb2pX+9S83snFyK28wONbPxZjbfzOaa2S3++py93gliztlrbWatzOxTM5vpx3yXvz6Xr3O8mDNznRs6ZV8+/ADNgKXA4UALYCbQN9txRcS3HOhca929wFB/eShwj7/c14+/JdDLf1/NMhDjacDxwJyGxAh8CpwEGDAG+G4W4h4G/DJG2ZyIG+gKHO8vtwUW+bHl7PVOEHPOXmv/+G385WJgKjAox69zvJgzcp0LpYZxArDEOfeFc24f8BJwQZZjSuYC4Bl/+Rngwoj1Lznn9jrnlgFL8N5fWjnnJgKbGxKjmXUF2jnnJjvvL/bZiH0yGXc8ORG3c26Nc+5zf7kcmA8cQg5f7wQxx5MLMTvn3A7/ZbH/48jt6xwv5ngaNeZCSRiHAKsiXq8m8R9zpjngv2Y23cyu99cd5JxbA95/RuBAf30uvZdUYzzEX669Pht+Zmaz/FtWoVsOORe3mfUEjsP7JpkX17tWzJDD19rMmplZKbAeeM85l/PXOU7MkIHrXCgJI9a9uVzqT3yyc+544LvATWZ2WoKyuf5eIH6MuRL7I8ARQH9gDfAPf31OxW1mbYDXgFudc9sTFY2xLitxx4g5p6+1c67KOdcf6I73zfuoBMVzOeaMXOdCSRirgUMjXncHyrIUSx3OuTL/93rgDbxbTOv8aiP+7/V+8Vx6L6nGuNpfrr0+o5xz6/z/dNXA44Rv6eVM3GZWjPfBO8o597q/Oqevd6yY8+Fa+3FuBSYAZ5Pj1zkkMuZMXedCSRifAb3NrJeZtQCGAKOzHBMAZra/mbUNLQPfBubgxXe1X+xq4N/+8mhgiJm1NLNeQG+8xqtsSClGv3pfbmaD/B4ZP4zYJ2NCHwa+7+Ndb8iRuP1zPAnMd87dH7EpZ693vJhz+VqbWRczO8Bfbg2cBSwgt69zzJgzdp3T0ZKfiz/AOXg9N5YCv812PBFxHY7Xi2EmMDcUG9AJeB9Y7P/uGLHPb/33sZA09zKKOOeLeFXdCrxvJ9fVJ0agxP9jXgo8hD/aQIbjfg6YDczy/0N1zaW4gVPwbg/MAkr9n3Ny+XoniDlnrzVwDDDDj20O8Ad/fS5f53gxZ+Q6a2gQEREJpFBuSYmISAMpYYiISCBKGCIiEogShoiIBKKEISIigShhSF4xs54WMfJswH2uMbNuAco8FOBYT5hZX3/5N6nEEeDYUXFGnkskFyhhSCG4BkiYMIJyzv3IOTfPf5lywjCzZgk2X0NEnLXOJZJ1ShiSj5qb2TP+QGuvmtl+AGb2BzP7zMzmmNkI81yM94DSKPPmCWhtZgPN7BPz5hT4NPSkPdDNzMaaNw/CvbFObGYTzKzEzO4GWvvHHOVvu9I/XqmZPRZKDma2w8z+ZGZTgZNSiHOCmZX4x7jMvLkL5pjZPRHx7DCzv/rvZYqZHeSvv8QvO9PMJqblX0EKT7qeVtWPftLxA/TEe6L4ZP/1U/jzABD9RO5zwHn+8gSgxF9uAXwBDPRftwOa4327/wJoD7QCVgCHxjh/5LF2RKzvA7wFFPuvHwZ+6C874NKIsknjjHyNV+tYCXTxY/0AuDDi2KH97wV+5y/PBg7xlw/I9r+bfprGj2oYko9WOec+9pefxxuWAuAbZjbVzGYD3wT6xdj3SGCNc+4zAOfcdudcpb/tfefcNufcHmAecFgKMZ0JDAA+M2/o6TPxhn0BqMIblC8kSJyRBgITnHMb/FhH4U0MBbAP+I+/PB0voQJ8DIw0sx/jTSAm0mDNsx2ASD3UHs/GmVkrvG/1Jc65VWY2DK+mUJvF2D9kb8RyFan9/zDgGefcr2Ns2+OcqwJvis2AcdY+djwVzrnQ+6mJ2Tl3g5mdCJwLlJpZf+fcpuBvR6Qu1TAkH/Uws5P85cuASYQ/dDeaNyfDxRHly/GmDQVvNNJuZjYQwMzamll9vzhVmDekN3iD1F1sZgf6x+1oZrFqKEHjjDQVON3MOvvtIpcBHyYKzMyOcM5Ndc79AdhI9BDXIvWiGobko/nA1Wb2GN6Ioo8453aZ2eN49+6X4w1pHzISeNTMduPNYfwD4H/94aF34w0RXR8jgFlm9rlz7goz+x3ezIlFeKPj3oTXFlLDObc1hThD+6wxs18D4/FqG+8455INRX2fmfX2y7+PNxqySINotFoREQlEt6RERCQQJQwREQlECUNERAJRwhARkUCUMEREJBAlDBERCUQJQ0REAvn/g5M7hQyIsngAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hyperparameters\n",
    "TRAIN_BATCH_SIZE = 200\n",
    "VAL_BATCH_SIZE = 50\n",
    "EPOCHS = 20\n",
    "\n",
    "# hardware device\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Using: %s\" % device)\n",
    "kwargs = {'num_workers': 0,\n",
    "          'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "# data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = TRAIN_BATCH_SIZE,\n",
    "                                           shuffle = True, drop_last = True, **kwargs)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size = VAL_BATCH_SIZE,\n",
    "                                         shuffle = False, drop_last = True, **kwargs)  \n",
    "\n",
    "# training objects\n",
    "model = LeNet5().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "# training loop\n",
    "train_curve = []\n",
    "val_curve = []\n",
    "best_loss = np.inf\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_losses = train(model, device, train_loader, optimizer, epoch)\n",
    "    val_losses, val_loss = validate(model, device, val_loader)\n",
    "    train_curve.extend(train_losses)\n",
    "    val_curve.extend(val_losses)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    # save best model\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"checkpoints/epoch_%d.pt\" % epoch)\n",
    "        \n",
    "# plot loss functions\n",
    "plt.plot(np.arange(EPOCHS * 168) + 1, train_curve, label = \"train\")\n",
    "plt.plot(np.arange(EPOCHS * 168) + 1, val_curve, label = \"val\")\n",
    "plt.legend()\n",
    "plt.xlabel('batch iterations')\n",
    "plt.ylabel('mean loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
